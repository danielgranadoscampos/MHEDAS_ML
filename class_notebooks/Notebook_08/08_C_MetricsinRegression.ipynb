{"cells":[{"cell_type":"markdown","metadata":{"id":"dFqdFxSJCZtk"},"source":["# Regression example\n","\n","## Metrics for model evaluation\n","\n"]},{"cell_type":"markdown","metadata":{"deletable":true,"editable":true,"id":"_fg3KmFVCZtl"},"source":["In a dataset after applying a regression model how to evaluate it. There are many metrics that we can use. We will be using mean absolute error (MAE), mean squared error (MSE, RMSE) and R squared (R^2).\n","\n","We are going to use a classic dataset called \"Wine\", which analyzes the biochemical quality of series of wines according to different types of varieties associated with their genotype.\n","\n","**Recipe Objective**:\n","* Step 1 - Import the library\n","* Step 2 - Setting up the Data\n","* Step 3 - Training model and calculating Metrics"]},{"cell_type":"markdown","source":["### Step 1: Import the library"],"metadata":{"id":"zH2amNXykxcN"}},{"cell_type":"code","execution_count":null,"metadata":{"deletable":true,"editable":true,"id":"VUs7lEqtCZtv"},"outputs":[],"source":["from sklearn import datasets\n","from sklearn import tree, model_selection\n","from sklearn.model_selection import train_test_split\n","from numpy import mean\n","from numpy import absolute\n","from numpy import sqrt"]},{"cell_type":"markdown","metadata":{"id":"3nMwHyQnUQDg"},"source":["We have imported datasets, tree, model_selection and test_train_split which are the libraries needed for the exercise.\n","\n"]},{"cell_type":"markdown","source":["### Step 2: Setting up the data"],"metadata":{"id":"wEm4F38Ak31V"}},{"cell_type":"markdown","source":["In the next step we will import the inbuilt \"Wine\" dataset, storing the data in \"x\" and the labels in \"y\". Once this is done, we will split the data into test and train, both \"x\" and \"y\".\n","\n","Then, we will use \"KFold\", which allows us to divide the datset into \"K\" folds, considering one of them as a validation set and the remaining folders as a training set, making \"K\" different combinations (learn more in https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html).\n"],"metadata":{"id":"xaSDOIpDk-EF"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"mvTePMITUQDg","executionInfo":{"status":"ok","timestamp":1708083808963,"user_tz":-60,"elapsed":327,"user":{"displayName":"toni Monleon","userId":"05269440626861479105"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"bd16f8dd-d259-4073-fc5f-48b3584d2f00"},"outputs":[{"output_type":"stream","name":"stdout","text":["X........................\n","[[1.423e+01 1.710e+00 2.430e+00 ... 1.040e+00 3.920e+00 1.065e+03]\n"," [1.320e+01 1.780e+00 2.140e+00 ... 1.050e+00 3.400e+00 1.050e+03]\n"," [1.316e+01 2.360e+00 2.670e+00 ... 1.030e+00 3.170e+00 1.185e+03]\n"," ...\n"," [1.327e+01 4.280e+00 2.260e+00 ... 5.900e-01 1.560e+00 8.350e+02]\n"," [1.317e+01 2.590e+00 2.370e+00 ... 6.000e-01 1.620e+00 8.400e+02]\n"," [1.413e+01 4.100e+00 2.740e+00 ... 6.100e-01 1.600e+00 5.600e+02]]\n","y........................\n","[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"," 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"," 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n"," 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n","(178, 13)\n"]}],"source":["#The wine dataset is a classic and very easy multi-class classification dataset.\n","#The copy of UCI ML Wine Data Set dataset is downloaded and modified to fit standard format from: https://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data\n","\n","#DATA:\n","seed = 42\n","dataset = datasets.load_wine()\n","X = dataset.data #data\n","y = dataset.target #labels (3 wine cultivars/varieties)\n","\n","#PRINT DATA:\n","print(\"X........................\")\n","print(X)\n","print(\"y........................\")\n","print(y)\n","\n","#dimension\n","print(X.shape)\n","\n"]},{"cell_type":"markdown","source":["Now split data in Training and test and obtain k-fols:\n","\n","k-fold cross-validation, is a technique used to evaluate the performance of machine learning models. It works by splitting your data into k folds (usually equal-sized) and performing the following steps:\n","\n","For each fold:\n","Train the model on k-1 folds of data (excluding the current fold).\n","Evaluate the model's performance on the remaining fold (held-out set).\n","Average the performance metrics across all folds."],"metadata":{"id":"hUufX9Esu8BF"}},{"cell_type":"code","source":["#split data into train 75% and test (25%)\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25) # 75 training, 25 test\n","\n","#obtain 10 kfolds to allow cross-validation, using shuffle= True ->specifies whether to shuffle the data before splitting it into folds for cross-validation. (\"Shuffle the cards before dealing.\" - \"Baraja las cartas antes de repartir.\")\n","kfold = model_selection.KFold(n_splits=10, random_state=seed, shuffle= True) #10 splits of data;"],"metadata":{"id":"wwc6ojgqt8tD"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BEDnlYCkUQDh"},"source":["### Step 3 - Training model and calculating Metrics\n"]},{"cell_type":"markdown","source":["Here we will be using DecisionTreeRegressor as our model\n","\n","\n","\n","*   tree.DecisionTreeRegressor is a powerful algorithm from the scikit-learn library used for regression tasks. It builds a tree-like structure to predict continuous target values based on input features\n","*   Easy to interpret: The tree structure provides a clear understanding of how the model arrives at its predictions.\n","*   Handles complex relationships: Can learn complex non-linear relationships between features and the target variable.\n","*   Robust to outliers: Less sensitive to outliers in the data compared to some other regression methods.\n","\n","\n","\n","\n"],"metadata":{"id":"2TUbb_auplVD"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"aqR6gubsUQDi"},"outputs":[],"source":["model = tree.DecisionTreeRegressor()"]},{"cell_type":"markdown","metadata":{"id":"yy8JHIkJUQDj"},"source":["Now we will be calculating different **metrics**. We will be using cross validation score to calculate the metrices (https://scikit-learn.org/stable/modules/cross_validation.html#cross-validation). So we will be printing the mean and standard deviation of all the scores (10 kfolds).\n","\n","##### **Calculating Mean Absolute Error (MAE)**"]},{"cell_type":"markdown","source":["Mean Absolute Error is the average of the sum of absolute difference between the actual values and the predicted values. A model with less MAE performs better than model with large MAE value"],"metadata":{"id":"hfIwGVw3Nhd8"}},{"cell_type":"markdown","source":["$MAE=\\frac{1}{N}\\cdot \\sum_{i=1}^{N} |y_{i}-\\hat{y}_{i}|$"],"metadata":{"id":"7gHWZsk7O79D"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"O1PISylCUQDk","outputId":"e683b601-3631-4454-8cb4-ed6720b5b64e","executionInfo":{"status":"ok","timestamp":1708084446832,"user_tz":-60,"elapsed":251,"user":{"displayName":"toni Monleon","userId":"05269440626861479105"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Mean Absolute Error:each kfold:.......................\n","[0.         0.14285714 0.07142857 0.15384615 0.23076923 0.23076923\n"," 0.15384615 0.07692308 0.07692308 0.07692308]\n","Mean of the Mean Absolute Error------------------------\n","Mean Absolute Error:  0.12142857142857141\n","Standard Deviation:  0.07046904116411021\n"]}],"source":["scoring = \"neg_mean_absolute_error\" #Calculating Mean Absolute Error for the train set\n","results = model_selection.cross_val_score(model, X_train, y_train, cv=kfold, scoring=scoring)\n","\n","print(\"Mean Absolute Error:each kfold:.......................\")\n","print(absolute(results))\n","print(\"Mean of the Mean Absolute Error------------------------\")\n","print(\"Mean Absolute Error: \", mean(absolute(results))); print(\"Standard Deviation: \", results.std())"]},{"cell_type":"markdown","metadata":{"id":"JCQkMsOuUQDm"},"source":["##### **Calculating Mean Squared Error (MSE)**\n","\n"]},{"cell_type":"markdown","source":["Mean Square Error is the average of the sum of square of the difference between actual and predicted values.\n"],"metadata":{"id":"WOoTPNCxQTu7"}},{"cell_type":"markdown","source":["$MSE=\\frac{1}{N}\\cdot \\sum_{i=1}^{N} ( y_{i}-\\hat{y}_{i})^2$"],"metadata":{"id":"-n1SPjU2RMJq"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pY4gfVt2UQDn","outputId":"e26ff5d6-411f-4592-907b-556913ac5ab1","executionInfo":{"status":"ok","timestamp":1708084487351,"user_tz":-60,"elapsed":271,"user":{"displayName":"toni Monleon","userId":"05269440626861479105"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Mean Squared Error:  0.09890109890109891\n","Standard Deviation:  0.07660846179311374\n"]}],"source":["scoring = \"neg_mean_squared_error\" #Calculating Mean squared error\n","results = model_selection.cross_val_score(model, X_train, y_train, cv=kfold, scoring=scoring)\n","print(); print(\"Mean Squared Error: \", mean(absolute(results))); print(\"Standard Deviation: \", results.std())"]},{"cell_type":"markdown","source":["There is also the Root Mean Square Error, which is the same as Mean Square Error but root of the MSE is considered while evaluating the model. RMSE is more sensitive to the presence of false data .i.e. outliers."],"metadata":{"id":"d_EZBfuZSShB"}},{"cell_type":"markdown","metadata":{"id":"Ws194zvTUQDo"},"source":["##### **Calculating R squared value**\n","\n"]},{"cell_type":"markdown","source":["RÂ² score also known as the coefficient of determination gives the measure of how good a model fits to a given dataset. It indicates how closer are the predicted values to the actual values. The RÂ² value ranges from 0 to 1."],"metadata":{"id":"2K5sVC7LRWBS"}},{"cell_type":"markdown","source":["$R^2=1-\\frac{\\sum_{i=1}( y_{i}-\\hat{y}_{i})^2}{\\sum_{i=1}( y_{i}-\\bar{y}_{i})^2}$"],"metadata":{"id":"BLuzTanERXTK"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"meqluqLnUQDo","outputId":"c0421a02-5887-4160-9bac-1bcea44919c6","executionInfo":{"status":"ok","timestamp":1708084510846,"user_tz":-60,"elapsed":314,"user":{"displayName":"toni Monleon","userId":"05269440626861479105"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","R squared val:  0.8075236912132073\n","Standard Deviation:  0.17957907480493432\n"]}],"source":["scoring = \"r2\" #Calculating R squared value\n","results = model_selection.cross_val_score(model, X_train, y_train, cv=kfold, scoring=scoring)\n","print(); print(\"R squared val: \", results.mean()); print(\"Standard Deviation: \", results.std())"]},{"cell_type":"markdown","metadata":{"id":"y8cU7gpaUQDp"},"source":["<!--NAVIGATION-->\n","Based partially in internet, only for teaching pourposes.\n","\n","See in: https://www.projectpro.io/recipes/use-regression-metrics-in-python"]}],"metadata":{"anaconda-cloud":{},"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3.7.7rc1 64-bit","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.7rc1"},"vscode":{"interpreter":{"hash":"5060c395ae64037ee8844c2173a43fa7410db02f7938ed2393fe6924352a78b7"}}},"nbformat":4,"nbformat_minor":0}