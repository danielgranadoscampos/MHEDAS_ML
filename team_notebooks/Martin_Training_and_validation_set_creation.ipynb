{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb1871a-72c9-4d6b-8e73-73a6c68763b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Training and Validation Set Creation\n",
    "\n",
    "# Approaches to Data Splitting. For our dataset with 100 samples across 5 balanced classes, here are appropriate splitting approaches that we can use:\n",
    "\n",
    "# a. Simple Train-Test Split (Stratified)\n",
    "\n",
    "# This approach involves splitting of the dataset (e.g. 80% train / 20% validation) stratified by class to keep class balance. This method is quick and easy \n",
    "# though performance is highly dependent on how lucky or unlucky that single split is.\n",
    "\n",
    "# Justification:\n",
    "# With only 100 samples, a 80-20 split gives us 80 training and 20 validation samples. Stratification ensures each class has the same proportion in both sets.\n",
    "\n",
    "\n",
    "# Splitting Approach\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Stratified split maintains class proportions\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.2, \n",
    "    stratify=y,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# we shall look at an example later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a35b6186-f9b0-4f68-98bd-3c8fa2065ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# b. K-Fold Cross-Validation (Stratified)\n",
    "\n",
    "# This approach involves splitting the data into k folds (like 5), keeping class proportions the same in each fold. Each fold is used as validation once, and an average\n",
    "# of the results is given. This approach gives a much better estimate of performance and reduces variance from single-split randomness. But it is more computationally\n",
    "# expensive.\n",
    "\n",
    "# Justification: With small datasets, K-Fold cross validation gives better utilization of data. 5 folds means that each validation set has 20 samples (like the \n",
    "# simple split), but you train on all data over multiple iterations.\n",
    "\n",
    "# The approach\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "for train_index, val_index in skf.split(X, y):\n",
    "    X_train, X_val = X[train_index], X[val_index]\n",
    "    y_train, y_val = y[train_index], y[val_index]\n",
    "\n",
    "# we can see an illustration of both approaches in the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f64a6ca2-91d5-4fb7-b0ee-37b26142487e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simple Split Validation Accuracy: 0.8\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         DCM       0.75      0.75      0.75         4\n",
      "         HCM       1.00      0.75      0.86         4\n",
      "        MINF       0.75      0.75      0.75         4\n",
      "         NOR       0.75      0.75      0.75         4\n",
      "          RV       0.80      1.00      0.89         4\n",
      "\n",
      "    accuracy                           0.80        20\n",
      "   macro avg       0.81      0.80      0.80        20\n",
      "weighted avg       0.81      0.80      0.80        20\n",
      "\n",
      "K-Fold CV Accuracy: 0.790 ± 0.080\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import (train_test_split, StratifiedKFold, cross_val_score)\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# read dataset\n",
    "data = pd.read_csv('ACDC_radiomics.csv')\n",
    "\n",
    "# create the features and target class\n",
    "X = data.drop(columns=['class'])  # Features\n",
    "y = data['class']  # Target variable (class labels)\n",
    "\n",
    "\n",
    "# 1. Simple stratified split\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "\n",
    "# Train a model\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Evaluate\n",
    "val_pred = model.predict(X_val_scaled)\n",
    "print(\"Simple Split Validation Accuracy:\", accuracy_score(y_val, val_pred))\n",
    "print(classification_report(y_val, val_pred))\n",
    "\n",
    "# 2. K-Fold CV evaluation\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "cv_scores = cross_val_score(\n",
    "    RandomForestClassifier(random_state=42),\n",
    "    X_scaled,\n",
    "    y,\n",
    "    cv=cv,\n",
    "    scoring='accuracy'\n",
    ")\n",
    "\n",
    "print(f\"K-Fold CV Accuracy: {np.mean(cv_scores):.3f} ± {np.std(cv_scores):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc1bf283-f08a-494b-b795-13bc5eabbb29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results show that both the Simple Split (80% train / 20% test) and 5-Fold Cross-Validation give comparable performance (~79-80% accuracy), \n",
    "# however the K-Fold CV provides additional insights about model stability (±0.08 standard deviation). \n",
    "\n",
    "\n",
    "# Key Observations: \n",
    "# Both the simple split and K-Fold CV show consistent accuracy (~80%), indicating no severe overfitting, but class-wise performance varies. \n",
    "# We observe that HCM achieves perfect precision (1.0) but lower recall (0.75), suggesting conservative predictions, while RV is the best-predicted class (F1=0.89) and \n",
    "# DCM, MINF, NORM lag behind (F1 = 0.75). The K-Fold CV’s ±0.08 standard deviation (71–87% range) reveals model stability depends on data splits, and this has been noted\n",
    "# a common issue with small datasets. This highlights the need to address class-specific biases and improve generalization, particularly for underperforming classes.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
